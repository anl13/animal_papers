## Animal Paper Collection (Ongoing)
[2022.01.02] To make it easy to track, I sort the papers using the timepoint I find them (not publication time), and add label badges to show paper features. 

[2021.11.28] I recommend [MMPose](https://github.com/open-mmlab/mmpose) for 2D animal pose estimation. It has collected various kinds of [datasets](https://github.com/open-mmlab/mmpose/blob/master/docs/tasks/2d_animal_keypoint.md).

[2021.07.16] I recommend CV4Animal workshop in CVPR 2021 (https://www.cv4animals.com/) because it is a good collection of recent advances in animal pose estimation area! 

Recently, markerless animal **motion capture** and **3D reconstruction** attracts more and more attention in computer vision community. Inspired by remarkable techniques for markerless human motion capture, a few excellent literatures appear for animal modeling and reconstruction such as [SMAL](http://smal.is.tue.mpg.de/
) and [DeepLabCut](http://www.mousemotorlab.org/deeplabcut). However, there is still a long way before computer vision methods could capture natural motion of arbitary animals in industrial-grade. 

Therefore, I contribute this repository to track every step towards the ultimate goal of high quality animal capture. If you want to add/remove an article, please send an email to [Liang An](https://anl13.github.io/)(al17 at mails dot tsinghua dot edu dot cn). Thank all the authors for their contribution and support.


<br>

<table><tbody> <tr> <td align="left" width=250>
<a href="https://deeplabcut.github.io/DeepLabCut/docs/intro.html?msclkid=94c16acabc5a11ec80efaafc9aaeb28c"><img src="teasers/Lauer2022.jpg"/></a></td>
<td align="left" width=550><em>Multi-animal pose estimation, identification and tracking with DeepLabCut</em><br>
<font size=2.5>Jessy Lauer</font>, 
<font size=2.5>Mu Zhou</font>, 
<font size=2.5>Shaokai Ye</font>, 
<font size=2.5>William Menegas</font>, 
<font size=2.5>Steffen Schneider</font>, 
<font size=2.5>Tanmay Nath</font>, 
<font size=2.5>Mohammed Mostafizur Rahman</font>, 
<font size=2.5>Valentina Di Santo</font>, 
<font size=2.5>Daniel Soberanes</font>, 
<font size=2.5>Guoping Feng</font>, 
<font size=2.5>Venkatesh N. Murthy</font>, 
<font size=2.5>George Lauder</font>, 
<font size=2.5>Catherine Dulac</font>, 
<font size=2.5>Mackenzie Weygandt Mathis</font>, 
<a href="https://www.mathislab.org/people"><font size=2.5>Alexander Mathis</font></a><br>
<font size=2.5>In Nature Methods 2022 </font><br>
<a href="https://www.nature.com/articles/s41592-022-01443-0"><img src="data/paper.png"></a> 
<a href="https://deeplabcut.github.io/DeepLabCut/docs/intro.html?msclkid=94c16acabc5a11ec80efaafc9aaeb28c"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-2d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-2d-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://sleap.ai/"><img src="teasers/Pereira2022.jpg"/></a></td>
<td align="left" width=550><em>SLEAP: A deep learning system for multi-animal pose tracking</em><br>
<a href="https://biophysics.princeton.edu/people/talmo-pereira"><font size=2.5>Talmo D. Pereira</font></a>, 
<font size=2.5>Nathaniel Tabris</font>, 
<font size=2.5>Arie Matsliah</font>, 
<font size=2.5>David M. Turner</font>, 
<font size=2.5>Junyu Li</font>, 
<font size=2.5>Shruthi Ravindranath</font>, 
<font size=2.5>Eleni S. Papadoyannis</font>, 
<font size=2.5>Edna Normand</font>, 
<font size=2.5>David S. Deutsch</font>, 
<font size=2.5>Z. Yan Wang</font>, 
<font size=2.5>Grace McKenzie-Smith</font>, 
<font size=2.5>Catalin C. Mitelut</font>, 
<font size=2.5>Marielisa Diez Castro</font>, 
<font size=2.5>John D'Uva</font>, 
<font size=2.5>Mikhail Kislin</font>, 
<a href="https://www.saneslab.com/"><font size=2.5>Dan H. Sanes</font></a>, 
<a href="https://lsi.princeton.edu/sarah-d-kocher"><font size=2.5>Sarah D. Kocher</font></a>, 
<a href="https://scholar.princeton.edu/wanglab/about"><font size=2.5>Samuel S.-H. Wang</font></a>, 
<a href="https://www.falknerlab.com/"><font size=2.5>Annegret L. Falkner</font></a>, 
<a href="https://molbio.princeton.edu/people/joshua-w-shaevitz"><font size=2.5>Joshua W. Shaevitz</font></a>, 
<a href="https://murthylab.princeton.edu/mala-murthy"><font size=2.5>Mala Murthy</font></a><br>
<font size=2.5>In Nature Methods 2022 </font><br>
<a href="https://www.nature.com/articles/s41592-022-01426-1"><img src="data/paper.png"></a> 
<a href="https://sleap.ai/"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-2d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-2d-9cf"></a><a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a><a href="https://img.shields.io/badge/animal-fly-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-fly-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://barc.is.tue.mpg.de/"><img src="teasers/Ruegg2022.jpg"/></a></td>
<td align="left" width=550><em>BARC: Learning to Regress 3D Dog Shape from Images by Exploiting Breed Information</em><br>
<a href="https://ps.is.mpg.de/person/nrueegg"><font size=2.5>Nadine Ruegg</font></a>, 
<a href="https://ps.is.mpg.de/person/szuffi"><font size=2.5>Silvia Zuffi</font></a>, 
<font size=2.5>Konrad Schindler</font>, 
<a href="https://ps.is.mpg.de/person/black"><font size=2.5>Michael J. Black</font></a><br>
<font size=2.5>In CVPR 2022 </font><br>
<a href="https://arxiv.org/pdf/2203.15536.pdf"><img src="data/paper.png"></a> 
<a href="https://barc.is.tue.mpg.de/"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/animal-dog-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-dog-yellowgreen"></a><a href="https://img.shields.io/badge/datatype-3d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-3d-9cf"></a><a href="https://img.shields.io/badge/datatype-mesh-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-mesh-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Luo2022.jpg"/></a></td>
<td align="left" width=550><em>Artemis: Articulated Neural Pets with Appearance and Motion Synthesis</em><br>
<font size=2.5>Haimin Luo</font>, 
<font size=2.5>Teng Xu</font>, 
<font size=2.5>Yuheng Jiang</font>, 
<font size=2.5>Chenglin Zhou</font>, 
<font size=2.5>Qiwei Qiu</font>, 
<font size=2.5>Yingliang Zhang</font>, 
<font size=2.5>Wei Yang</font>, 
<a href="https://www.xu-lan.com/"><font size=2.5>Lan Xu</font></a>, 
<a href="https://vic.shanghaitech.edu.cn/vrvc/en/people/jingyi-yu/"><font size=2.5>Jingyi Yu</font></a><br>
<font size=2.5>In arxiv 2022 </font><br>
<a href="https://arxiv.org/abs/2202.05628"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/datatype-3d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-3d-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://github.com/chrelli/3DDD_social_mouse_tracker/"><img src="teasers/Ebbesen2020.jpg"/></a></td>
<td align="left" width=550><em>Automatic mapping of multiplexed social receptive fields by deep learning and GPU-accelerated 3D videography</em><br>
<font size=2.5>Christian L. Ebbesen</font>, 
<a href="http://froemkelab.med.nyu.edu/people"><font size=2.5>Robert C. Froemke</font></a><br>
<font size=2.5>In Nature Communications 2022 </font><br>
<a href="https://www.biorxiv.org/content/10.1101/2020.05.21.109629v2"><img src="data/paper.png"></a> 
<a href="https://github.com/chrelli/3DDD_social_mouse_tracker/"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-3d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-3d-9cf"></a><a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://banmo-www.github.io/"><img src="teasers/Yang2022.jpg"/></a></td>
<td align="left" width=550><em>BANMo: Building Animatable 3D Neural Models from Many Casual Videos</em><br>
<a href="https://gengshan-y.github.io/"><font size=2.5>Gengshan Yang</font></a>, 
<a href="https://minhpvo.github.io/"><font size=2.5>Minh Vo</font></a>, 
<a href="https://nneverova.github.io/"><font size=2.5>Natalia Neverova</font></a>, 
<a href="https://www.cs.cmu.edu/~deva/"><font size=2.5>Deva Ramanan</font></a>, 
<a href="https://www.robots.ox.ac.uk/~vedaldi/"><font size=2.5>Andrea Vedaldi</font></a>, 
<a href="https://jhugestar.github.io/"><font size=2.5>Hanbyul Joo</font></a><br>
<font size=2.5>In CVPR 2022 </font><br>
<a href="https://arxiv.org/abs/2112.12761"><img src="data/paper.png"></a> 
<a href="https://banmo-www.github.io/"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/animal-quadruped-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-quadruped-yellowgreen"></a><a href="https://img.shields.io/badge/datatype-dense%20surface-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-dense%20surface-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Gunel2021.jpg"/></a></td>
<td align="left" width=550><em>Overcoming the Domain Gap in Neural Action Representations</em><br>
<font size=2.5>Semih Gunel</font>, 
<font size=2.5>Florian Aymanns</font>, 
<font size=2.5>Sina Honari</font>, 
<font size=2.5>Pavan Ramdya</font>, 
<font size=2.5>Pascal Fua</font><br>
<font size=2.5>In arxiv 2021 </font><br>
<a href="https://arxiv.org/pdf/2112.01176.pdf"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/animal-fly-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-fly-yellowgreen"></a><a href="https://img.shields.io/badge/topic-behavior-orange" align="bottom"><img src="https://img.shields.io/badge/topic-behavior-orange"></a><a href="https://img.shields.io/badge/datatype-3d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-3d-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Nayak2022.jpg"/></a></td>
<td align="left" width=550><em>Incremental Learning for Animal Pose Estimation using RBF k-DPP</em><br>
<font size=2.5>Gaurav Kumar Nayak</font>, 
<a href="https://het-shah.github.io/"><font size=2.5>Het Shah</font></a>, 
<a href="http://visual-computing.in/wp-content/uploads/2017/08/anirban-chakraborty.html"><font size=2.5>Anirban Chakraborty</font></a><br>
<font size=2.5>In arxiv 2021 </font><br>
<a href="https://arxiv.org/pdf/2110.13598.pdf"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/animal-quadruped-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-quadruped-yellowgreen"></a><a href="https://img.shields.io/badge/datatype-2d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-2d-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Jiang2020.jpg"/></a></td>
<td align="left" width=550><em>Muti-view Mouse Social Behaviour Recognition with Deep Graphic Model</em><br>
<font size=2.5>Zheheng Jiang</font>, 
<font size=2.5>Feixiang Zhou</font>, 
<font size=2.5>Aite Zhao</font>, 
<font size=2.5>Xin Li</font>, 
<font size=2.5>Ling Li</font>, 
<a href="https://dl.acm.org/profile/81100159571"><font size=2.5>Dacheng Tao</font></a>, 
<a href="http://www.dcs.bbk.ac.uk/~xuelong/"><font size=2.5>Xuelong Li</font></a>, 
<a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou"><font size=2.5>Huiyu Zhou</font></a><br>
<font size=2.5>In TIP 2021 </font><br>
<a href="https://arxiv.org/pdf/2011.02451.pdf"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a><a href="https://img.shields.io/badge/topic-behavior-orange" align="bottom"><img src="https://img.shields.io/badge/topic-behavior-orange"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Han2021.jpg"/></a></td>
<td align="left" width=550><em>MouseVenue3D: A Markerless Three-Dimension Behavioral Tracking System for Matching Two-Photon Brain Imaging in Free-Moving Mice</em><br>
<font size=2.5>Yaning Han</font>, 
<font size=2.5>Kang Huang</font>, 
<font size=2.5>Ke Chen</font>, 
<font size=2.5>Hongli Pan</font>, 
<font size=2.5>Furong Ju</font>, 
<font size=2.5>Yueyue Long</font>, 
<font size=2.5>Gao Gao</font>, 
<font size=2.5>Runlong Wu</font>, 
<font size=2.5>Aimin Wang</font>, 
<font size=2.5>Liping Wang</font>, 
<font size=2.5>Pengfei Wei</font><br>
<font size=2.5>In Neuroscience Bulletin 2021 </font><br>
<a href="https://link.springer.com/article/10.1007%2Fs12264-021-00778-6"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a><a href="https://img.shields.io/badge/datatype-3d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-3d-9cf"></a><a href="https://img.shields.io/badge/topic-brain-orange" align="bottom"><img src="https://img.shields.io/badge/topic-brain-orange"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Straw2010.jpg"/></a></td>
<td align="left" width=550><em>Multi-camera real-time threedimensional tracking of multiple flying animals</em><br>
<a href="https://strawlab.org/"><font size=2.5>Andrew D. Straw</font></a>, 
<font size=2.5>Kristin Branson</font>, 
<font size=2.5>Titus R. Neumann</font>, 
<a href="https://www.bbe.caltech.edu/people/michael-h-dickinson"><font size=2.5>Michael H. Dickinson</font></a><br>
<font size=2.5>In J. R. Soc. Interface 2011 </font><br>
<a href="https://royalsocietypublishing.org/doi/pdf/10.1098/rsif.2010.0230"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/animal-fly-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-fly-yellowgreen"></a><a href="https://img.shields.io/badge/datatype-3d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-3d-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://neuroethology.github.io/MARS/"><img src="teasers/Segalin2021.jpg"/></a></td>
<td align="left" width=550><em>The Mouse Action Recognition System (MARS) software pipeline for automated analysis of social behaviors in mice</em><br>
<font size=2.5>Cristina Segalin</font>, 
<font size=2.5>Jalani Williams</font>, 
<font size=2.5>Tomomi Karigo</font>, 
<font size=2.5>May Hui</font>, 
<font size=2.5>Moriel Zelikowsky</font>, 
<font size=2.5>Jennifer J Sun</font>, 
<font size=2.5>Pietro Perona</font>, 
<font size=2.5>David J Anderson</font>, 
<font size=2.5>Ann Kennedy</font><br>
<font size=2.5>In eLife 2021 </font><br>
<a href="https://elifesciences.org/articles/63720.pdf"><img src="data/paper.png"></a> 
<a href="https://neuroethology.github.io/MARS/"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a><a href="https://img.shields.io/badge/datatype-2d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-2d-9cf"></a><a href="https://img.shields.io/badge/topic-dataset-orange" align="bottom"><img src="https://img.shields.io/badge/topic-dataset-orange"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Sun2021-2.jpg"/></a></td>
<td align="left" width=550><em>Self-Supervised Keypoint Discovery in Behavioral Videos</em><br>
<font size=2.5>Jennifer J. Sun</font>, 
<font size=2.5>Serim Ryou</font>, 
<font size=2.5>Roni Goldshmid</font>, 
<font size=2.5>Brandon Weissbourd</font>, 
<font size=2.5>John Dabiri</font>, 
<font size=2.5>David J. Anderson</font>, 
<font size=2.5>Ann Kennedy</font>, 
<font size=2.5>Yisong Yue</font>, 
<font size=2.5>Pietro Perona</font><br>
<font size=2.5>In arxiv 2021 </font><br>
<a href="https://arxiv.org/pdf/2112.05121.pdf"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/datatype-2d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-2d-9cf"></a><a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a><a href="https://img.shields.io/badge/topic-behavior-orange" align="bottom"><img src="https://img.shields.io/badge/topic-behavior-orange"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://www.aicrowd.com/challenges/multi-agent-behavior-representation-modeling-measurement-and-applications"><img src="teasers/Sun2021.jpg"/></a></td>
<td align="left" width=550><em>The Multi-Agent Behavior Dataset: Mouse Dyadic Social Interactions</em><br>
<font size=2.5>Jennifer J. Sun</font>, 
<font size=2.5>Tomomi Karigo</font>, 
<font size=2.5>Dipam Chakraborty</font>, 
<font size=2.5>Sharada P. Mohanty</font>, 
<font size=2.5>David J. Anderson</font>, 
<font size=2.5>Pietro Perona</font>, 
<font size=2.5>Yisong Yue</font>, 
<font size=2.5>Ann Kennedy</font><br>
<font size=2.5>In NeurIPS (Dataset & Benchmarks) 2021 </font><br>
<a href="https://deepai.org/publication/the-multi-agent-behavior-dataset-mouse-dyadic-social-interactions"><img src="data/paper.png"></a> 
<a href="https://www.aicrowd.com/challenges/multi-agent-behavior-representation-modeling-measurement-and-applications"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a><a href="https://img.shields.io/badge/datatype-2d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-2d-9cf"></a><a href="https://img.shields.io/badge/topic-dataset-orange" align="bottom"><img src="https://img.shields.io/badge/topic-dataset-orange"></a><a href="https://img.shields.io/badge/topic-behavior-orange" align="bottom"><img src="https://img.shields.io/badge/topic-behavior-orange"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="http://sites.google.com/view/task-programming"><img src="teasers/Sun2021-1.jpg"/></a></td>
<td align="left" width=550><em>Task Programming: Learning Data Efficient Behavior Representations</em><br>
<font size=2.5>Jennifer J. Sun</font>, 
<font size=2.5>Ann Kennedy</font>, 
<font size=2.5>Eric Zhan</font>, 
<font size=2.5>David J. Anderson</font>, 
<font size=2.5>Yisong Yue</font>, 
<font size=2.5>Pietro Perona</font><br>
<font size=2.5>In CVPR 2021 </font>(<b><font size=2.5>Best Student Paper Award</font></b>)<br>
<a href="http://export.arxiv.org/pdf/2011.13917"><img src="data/paper.png"></a> 
<a href="http://sites.google.com/view/task-programming"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/topic-behavior-orange" align="bottom"><img src="https://img.shields.io/badge/topic-behavior-orange"></a><a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Li2021-3.jpg"/></a></td>
<td align="left" width=550><em>Coarse-to-fine Animal Pose and Shape Estimation</em><br>
<a href="https://chaneyddtt.github.io/"><font size=2.5>Chen Li</font></a>, 
<a href="https://www.comp.nus.edu.sg/~leegh/"><font size=2.5>Gim Hee Lee</font></a><br>
<font size=2.5>In NeurIPS 2021 </font><br>
<a href="https://arxiv.org/pdf/2111.08176.pdf"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/datatype-mesh-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-mesh-9cf"></a><a href="https://img.shields.io/badge/animal-dog-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-dog-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Voloh2021.jpg"/></a></td>
<td align="left" width=550><em>Hierarchical organization of rhesus macaque behavior</em><br>
<font size=2.5>Benjamin Voloh</font>, 
<font size=2.5>Benjamin R. Eisenreich</font>, 
<font size=2.5>David J-N. Maisson</font>, 
<font size=2.5>R. Becket Ebitz</font>, 
<font size=2.5>Hyun Soo Park</font>, 
<font size=2.5>Benjamin Y. Hayden</font>, 
<font size=2.5>Jan Zimmermann</font><br>
<font size=2.5>In biorxiv 2021 </font><br>
<a href="https://doi.org/10.1101/2021.11.15.468721"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/animal-monkey-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-monkey-yellowgreen"></a><a href="https://img.shields.io/badge/topic-behavior-orange" align="bottom"><img src="https://img.shields.io/badge/topic-behavior-orange"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Marshall2021.jpg"/></a></td>
<td align="left" width=550><em>Leaving Flatland: Advances in 3D behavioral measurement</em><br>
<a href="https://neurotree.org/neurotree/peopleinfo.php?pid=663448"><font size=2.5>Jesse D. Marshall</font></a>, 
<font size=2.5>Tianqing Li</font>, 
<font size=2.5>Joshua H. Wu</font>, 
<font size=2.5>Timothy W. Dunn</font><br>
<font size=2.5>In arxiv 2021 </font><br>
<a href="https://arxiv.org/ftp/arxiv/papers/2112/2112.01987.pdf"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/datatype-3d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-3d-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Kim2021.jpg"/></a></td>
<td align="left" width=550><em>Unified 3D Mesh Recovery of Humans and Animals by Learning Animal Exercise</em><br>
<font size=2.5>Kim Youwang</font>, 
<font size=2.5>Kim Ji-Yeon</font>, 
<font size=2.5>Kyungdon Joo</font>, 
<font size=2.5>Tae-Hyun Oh</font><br>
<font size=2.5>In BMVC 2021 </font><br>
<a href="https://arxiv.org/pdf/2111.02450.pdf"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/datatype-mesh-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-mesh-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://anipose.readthedocs.io/en/latest/index.html"><img src="teasers/Karashchuk2021.jpg"/></a></td>
<td align="left" width=550><em>Anipose: a toolkit for robust markerless 3D pose estimation</em><br>
<a href="https://github.com/lambdaloop"><font size=2.5>Pierre Karashchuk</font></a>, 
<font size=2.5>Katie L. Rupp</font>, 
<font size=2.5>Evyn S. Dickinson</font>, 
<font size=2.5>SarahWalling-Bell</font>, 
<font size=2.5>Elischa Sanders</font>, 
<a href="https://www.salk.edu/scientist/eiman-azim/"><font size=2.5>Eiman Azim</font></a>, 
<a href="https://www.bingbrunton.com/"><font size=2.5>Bingni W. Brunton</font></a>, 
<a href="http://faculty.washington.edu/tuthill/"><font size=2.5>John C. Tuthill</font></a><br>
<font size=2.5>In Cell Reports (Resource) 2021 </font><br>
<a href="https://www.sciencedirect.com/science/article/pii/S2211124721011797?via%3Dihub"><img src="data/paper.png"></a> 
<a href="https://anipose.readthedocs.io/en/latest/index.html"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-3d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-3d-9cf"></a><a href="https://img.shields.io/badge/animal-fly-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-fly-yellowgreen"></a><a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Le2021.jpg"/></a></td>
<td align="left" width=550><em>Multimodal-based Scene-Aware Framework for Aquatic Animal Segmentation</em><br>
<font size=2.5>Minh-Quan Le</font>, 
<font size=2.5>Trung-Nghia Le</font>, 
<font size=2.5>Tam V. Nguyen</font>, 
<font size=2.5>Isao Echizen</font>, 
<font size=2.5>Minh-Triet Tran</font><br>
<font size=2.5>In arxiv 2021 </font><br>
<a href="https://arxiv.org/pdf/2112.06193.pdf"><img src="data/paper.png"></a> 
</td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Fujii2021.jpg"/></a></td>
<td align="left" width=550><em>Learning interaction rules from multi-animal trajectories via augmented behavioral models</em><br>
<font size=2.5>Keisuke Fujii</font>, 
<font size=2.5>Naoya Takeishi</font>, 
<font size=2.5>Kazushi Tsutsui</font>, 
<font size=2.5>Emyo Fujioka</font>, 
<font size=2.5>Nozomi Nishiumi</font>, 
<font size=2.5>Ryoya Tanaka</font>, 
<font size=2.5>Mika Fukushiro</font>, 
<font size=2.5>Kaoru Ide</font>, 
<font size=2.5>Hiroyoshi Kohno</font>, 
<font size=2.5>Ken Yoda</font>, 
<font size=2.5>Susumu Takahashi</font>, 
<font size=2.5>Shizuko Hiryu</font>, 
<a href="http://en.kawahara-lab.org/~kawahara/"><font size=2.5>Yoshinobu Kawahara</font></a><br>
<font size=2.5>In NeurIPS 2021 </font><br>
<a href="https://arxiv.org/pdf/2107.05326.pdf"><img src="data/paper.png"></a> 
</td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://figshare.com/projects/The_PAIR-R24M_Dataset_for_Multi-animal_3D_Pose_Estimation/115587"><img src="teasers/Marshall2021-2.jpg"/></a></td>
<td align="left" width=550><em>The PAIR-R24M Dataset for Multi-animal 3D Pose Estimation</em><br>
<font size=2.5>Jesse Marshall</font>, 
<font size=2.5>Ugne Klibaite</font>, 
<font size=2.5>Amanda Gellis</font>, 
<font size=2.5>Diego Aldarondo</font>, 
<a href="https://oeb.harvard.edu/people/bence-p-olveczky"><font size=2.5>Bence O¨lveczky</font></a>, 
<font size=2.5>Tim Dunn</font><br>
<font size=2.5>In NeurIPS 2021 </font><br>
<a href="https://openreview.net/pdf?id=-wVVl_UPr8"><img src="data/paper.png"></a> 
<a href="https://figshare.com/projects/The_PAIR-R24M_Dataset_for_Multi-animal_3D_Pose_Estimation/115587"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-3d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-3d-9cf"></a><a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a><a href="https://img.shields.io/badge/topic-dataset-orange" align="bottom"><img src="https://img.shields.io/badge/topic-dataset-orange"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Vidal2021.jpg"/></a></td>
<td align="left" width=550><em>Across-animal odor decoding by probabilistic manifold alignment</em><br>
<font size=2.5>Pedro Herrero-Vidal</font>, 
<font size=2.5>Dmitry Rinberg</font>, 
<a href="https://as.nyu.edu/content/nyu-as/as/faculty/cristina-savin.html"><font size=2.5>Cristina Savin</font></a><br>
<font size=2.5>In NeurIPS 2021 </font><br>
<a href="https://www.biorxiv.org/content/10.1101/2021.06.06.447279v1.full.pdf"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://github.com/rabbityl/DeformingThings4D"><img src="teasers/Li2021-2.jpg"/></a></td>
<td align="left" width=550><em>4DComplete: Non-Rigid Motion Estimation Beyond the Observable Surface</em><br>
<font size=2.5>Yang Li</font>, 
<font size=2.5>Hikari Takehara</font>, 
<font size=2.5>Takafumi Taketomi</font>, 
<font size=2.5>Bo Zheng</font>, 
<a href="https://niessnerlab.org/"><font size=2.5>Matthias Nießner</font></a><br>
<font size=2.5>In ICCV 2021 </font><br>
<a href="https://arxiv.org/pdf/2105.01905.pdf"><img src="data/paper.png"></a> 
<a href="https://github.com/rabbityl/DeformingThings4D"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-dense%20surface-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-dense%20surface-9cf"></a><a href="https://img.shields.io/badge/topic-dataset-orange" align="bottom"><img src="https://img.shields.io/badge/topic-dataset-orange"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Shapovalov2021.jpg"/></a></td>
<td align="left" width=550><em>DensePose 3D: Lifting Canonical Surface Maps of Articulated Objects to the Third Dimension</em><br>
<font size=2.5>Roman Shapovalov</font>, 
<font size=2.5>David Novotny</font>, 
<font size=2.5>Benjamin Graham</font>, 
<font size=2.5>Patrick Labatut</font>, 
<font size=2.5>Andrea Vedaldi</font><br>
<font size=2.5>In ICCV 2021 </font><br>
<a href="https://openaccess.thecvf.com/content/ICCV2021/html/Shapovalov_DensePose_3D_Lifting_Canonical_Surface_Maps_of_Articulated_Objects_to_ICCV_2021_paper.html"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/datatype-dense%20surface-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-dense%20surface-9cf"></a><a href="https://img.shields.io/badge/animal-quadruped-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-quadruped-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Ebbesen2021.jpg"/></a></td>
<td align="left" width=550><em>Body language signals for rodent social communication</em><br>
<font size=2.5>Christian L. Ebbesen</font>, 
<a href="https://med.nyu.edu/faculty/robert-c-froemke"><font size=2.5>Robert C. Froemke</font></a><br>
<font size=2.5>In Current Opinion in Neurobiology 2021 </font><br>
<a href="https://europepmc.org/backend/ptpmcrender.fcgi?accid=PMC8243782&blobtype=pdf"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Langford2010.jpg"/></a></td>
<td align="left" width=550><em>coding of facial expressions of pain in the laboratory mouse</em><br>
<font size=2.5>Dale J Langford</font>, 
<font size=2.5>Andrea L Bailey</font>, 
<font size=2.5>Mona Lisa Chanda</font>, 
<font size=2.5>Sarah E Clarke</font>, 
<font size=2.5>Tanya E Drummond</font>, 
<font size=2.5>Stephanie Echols</font>, 
<font size=2.5>Sarah Glick</font>, 
<font size=2.5>Joelle Ingrao</font>, 
<font size=2.5>Tammy Klassen-Ross</font>, 
<font size=2.5>Michael L LaCroix-Fralish</font>, 
<font size=2.5>Lynn Matsumiya</font>, 
<font size=2.5>Robert E Sorge</font>, 
<font size=2.5>Susana G Sotocinal</font>, 
<font size=2.5>John M Tabaka</font>, 
<font size=2.5>David Wong</font>, 
<font size=2.5>Arn M J M van den Maagdenberg</font>, 
<font size=2.5>Michel D Ferrari</font>, 
<font size=2.5>Kenneth D Craig</font>, 
<font size=2.5>Jeffrey S Mogil</font><br>
<font size=2.5>In Nature Methods (brief communications) 2010 </font><br>
<a href="https://www.nature.com/articles/nmeth.1455"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a><a href="https://img.shields.io/badge/topic-face-orange" align="bottom"><img src="https://img.shields.io/badge/topic-face-orange"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://github.com/AlexTheBad/AP-10K"><img src="teasers/Yu2021.jpg"/></a></td>
<td align="left" width=550><em>AP-10K: A Benchmark for Animal Pose Estimation in the Wild</em><br>
<font size=2.5>Hang Yu</font>, 
<font size=2.5>Yufei Xu</font>, 
<font size=2.5>Jing Zhang</font>, 
<font size=2.5>Wei Zhao</font>, 
<font size=2.5>Ziyu Guan</font>, 
<a href="https://www.sydney.edu.au/engineering/about/our-people/academic-staff/dacheng-tao.html"><font size=2.5>Dacheng Tao</font></a><br>
<font size=2.5>In NeurIPS 2021 </font><br>
<a href="https://arxiv.org/pdf/2108.12617.pdf"><img src="data/paper.png"></a> 
<a href="https://github.com/AlexTheBad/AP-10K"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-2d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-2d-9cf"></a><a href="https://img.shields.io/badge/topic-dataset-orange" align="bottom"><img src="https://img.shields.io/badge/topic-dataset-orange"></a><a href="https://img.shields.io/badge/animal-quadruped-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-quadruped-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://deepimagej.github.io/deepimagej/"><img src="teasers/Mariscal2021.jpg"/></a></td>
<td align="left" width=550><em>DeepImageJ: A user-friendly environment to run deep learning models in ImageJ</em><br>
<font size=2.5>Estibaliz Gómez-de-Mariscal</font>, 
<font size=2.5>Carlos García-López-de-Haro</font>, 
<font size=2.5>Wei Ouyang</font>, 
<font size=2.5>Laurène Donati</font>, 
<font size=2.5>Emma Lundberg</font>, 
<font size=2.5>Michael Unser</font>, 
<font size=2.5>Arrate Muñoz-Barrutia</font>, 
<a href="https://people.epfl.ch/daniel.sage/?lang=en"><font size=2.5>Daniel Sage</font></a><br>
<font size=2.5>In Nature Methods (brief communication) 2021 </font><br>
<a href="https://www.nature.com/articles/s41592-021-01262-9.pdf"><img src="data/paper.png"></a> 
<a href="https://deepimagej.github.io/deepimagej/"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-2d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-2d-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://idtrackerai.readthedocs.io/en/latest/"><img src="teasers/Ferrero2019.jpg"/></a></td>
<td align="left" width=550><em>idtracker.ai: tracking all individuals in small or large collectives of unmarked animals</em><br>
<a href="https://www.researchgate.net/profile/Francisco_Romero-Ferrero"><font size=2.5>Francisco Romero-Ferrero</font></a>, 
<font size=2.5>Mattia G. Bergomi</font>, 
<font size=2.5>Robert C. Hinz</font>, 
<font size=2.5>Francisco J. H. Heras</font>, 
<a href="http://www.neuro.fchampalimaud.org/en/person/276/"><font size=2.5>Gonzalo G. de Polavieja</font></a><br>
<font size=2.5>In Nature Methods (Brief Communication) 2019 </font><br>
<a href="https://arxiv.org/abs/1803.04351"><img src="data/paper.png"></a> 
<a href="https://idtrackerai.readthedocs.io/en/latest/"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/animal-fly-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-fly-yellowgreen"></a><a href="https://img.shields.io/badge/datatype-2d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-2d-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="http://openmonkeychallenge.com/"><img src="teasers/Yao2021.jpg"/></a></td>
<td align="left" width=550><em>OpenMonkeyChallenge: Dataset and Benchmark Challenges for Pose Tracking of Non-human Primates</em><br>
<font size=2.5>Yuan Yao</font>, 
<font size=2.5>Abhiraj Mohan</font>, 
<font size=2.5>Eliza Bliss-Moreau</font>, 
<font size=2.5>Kristine Coleman</font>, 
<font size=2.5>Sienna M. Freeman</font>, 
<font size=2.5>Christopher J. Machado</font>, 
<font size=2.5>Jessica Raper</font>, 
<font size=2.5>Jan Zimmermann</font>, 
<font size=2.5>Benjamin Y. Hayden</font>, 
<font size=2.5>Hyun Soo Park</font><br>
<font size=2.5>In biorxiv 2021 </font><br>
<a href="https://www.biorxiv.org/content/10.1101/2021.09.08.459549v1.full.pdf"><img src="data/paper.png"></a> 
<a href="http://openmonkeychallenge.com/"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/animal-monkey-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-monkey-yellowgreen"></a><a href="https://img.shields.io/badge/topic-dataset-orange" align="bottom"><img src="https://img.shields.io/badge/topic-dataset-orange"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Banik2021.jpg"/></a></td>
<td align="left" width=550><em>A Novel Dataset for Keypoint Detection of Quadruped Animals from Images</em><br>
<font size=2.5>Prianka Banik</font>, 
<font size=2.5>Lin Li</font>, 
<font size=2.5>Xishuang Dong</font><br>
<font size=2.5>In arxiv 2021 </font><br>
<a href="https://arxiv.org/pdf/2108.13958.pdf"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/animal-quadruped-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-quadruped-yellowgreen"></a><a href="https://img.shields.io/badge/topic-dataset-orange" align="bottom"><img src="https://img.shields.io/badge/topic-dataset-orange"></a><a href="https://img.shields.io/badge/datatype-2d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-2d-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://nely-epfl.github.io/NeuroMechFly/"><img src="teasers/Rios2021.jpg"/></a></td>
<td align="left" width=550><em>NeuroMechFly, a neuromechanical model of adult Drosophila melanogaster</em><br>
<font size=2.5>Victor Lobato Rios</font>, 
<font size=2.5>Pembe Gizem Ozdil</font>, 
<font size=2.5>Shravan Tata Ramalingasetty</font>, 
<font size=2.5>Jonathan Arreguit</font>, 
<a href="https://www.epfl.ch/labs/biorob/people/ijspeert/"><font size=2.5>Auke Jan Ijspeert</font></a>, 
<a href="https://people.epfl.ch/pavan.ramdya"><font size=2.5>Pavan Ramdya</font></a><br>
<font size=2.5>In biorxiv 2021 </font><br>
<a href="https://www.biorxiv.org/content/10.1101/2021.04.17.440214v2"><img src="data/paper.png"></a> 
<a href="https://nely-epfl.github.io/NeuroMechFly/"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/animal-fly-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-fly-yellowgreen"></a><a href="https://img.shields.io/badge/datatype-mesh-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-mesh-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Neverova2021.jpg"/></a></td>
<td align="left" width=550><em>Discovering Relationships between Object Categories via Universal Canonical Maps</em><br>
<font size=2.5>Natalia Neverova</font>, 
<font size=2.5>Artsiom Sanakoyeu</font>, 
<font size=2.5>Patrick Labatut</font>, 
<font size=2.5>David Novotny</font>, 
<a href="https://www.robots.ox.ac.uk/~vedaldi/"><font size=2.5>Andrea Vedaldi</font></a><br>
<font size=2.5>In CVPR 2021 </font><br>
<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Neverova_Discovering_Relationships_Between_Object_Categories_via_Universal_Canonical_Maps_CVPR_2021_paper.pdf"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/datatype-dense%20surface-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-dense%20surface-9cf"></a><a href="https://img.shields.io/badge/animal-quadruped-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-quadruped-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Sheppard2020.jpg"/></a></td>
<td align="left" width=550><em>Gait-level analysis of mouse open field behavior using deep learning-based pose estimation</em><br>
<font size=2.5>Keith Sheppard</font>, 
<font size=2.5>Justin Gardin</font>, 
<font size=2.5>Gautam Sabnis</font>, 
<font size=2.5>Asaf Peer</font>, 
<font size=2.5>Megan Darrell</font>, 
<font size=2.5>Sean Deats</font>, 
<font size=2.5>Brian Geuther</font>, 
<font size=2.5>Cathleen M. Lutz</font>, 
<a href="https://www.kumarlab.org/"><font size=2.5>Vivek Kumar</font></a><br>
<font size=2.5>In biorxiv 2020 </font><br>
<a href="https://www.biorxiv.org/content/10.1101/2020.12.29.424780v2.full.pdf"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a><a href="https://img.shields.io/badge/topic-behavior-orange" align="bottom"><img src="https://img.shields.io/badge/topic-behavior-orange"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://github.com/NeLy-EPFL/LiftPose3D"><img src="teasers/Gosztolai2020.jpg"/></a></td>
<td align="left" width=550><em>LiftPose3D, a deep learning-based approach for transforming two-dimensional to three-dimensional poses in laboratory animals</em><br>
<font size=2.5>Adam Gosztolai</font>, 
<font size=2.5>Semih Gunel</font>, 
<font size=2.5>Marco Pietro Abrate</font>, 
<font size=2.5>Daniel Morales</font>, 
<font size=2.5>Victor Lobato Rios</font>, 
<a href="https://www.cs.ubc.ca/~rhodin/"><font size=2.5>Helge Rhodin</font></a>, 
<font size=2.5>Pascal Fua</font>, 
<a href="https://www.epfl.ch/labs/ramdya-lab/"><font size=2.5>Pavan Ramdya</font></a><br>
<font size=2.5>In Nature Methods 2021 </font><br>
<a href="https://www.nature.com/articles/s41592-021-01226-z.pdf"><img src="data/paper.png"></a> 
<a href="https://github.com/NeLy-EPFL/LiftPose3D"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-3d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-3d-9cf"></a><a href="https://img.shields.io/badge/animal-fly-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-fly-yellowgreen"></a><a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a><a href="https://img.shields.io/badge/animal-monkey-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-monkey-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://github.com/spoonsso/DANNCE"><img src="teasers/Dunn2021.jpg"/></a></td>
<td align="left" width=550><em>Geometric deep learning enables 3D kinematic profiling across species and environments</em><br>
<font size=2.5>Timothy W. Dunn</font>, 
<font size=2.5>Jesse D. Marshall</font>, 
<font size=2.5>Kyle S. Severson</font>, 
<font size=2.5>Diego E. Aldarondo</font>, 
<font size=2.5>David G. C. Hildebrand</font>, 
<font size=2.5>Selmaan N. Chettih</font>, 
<font size=2.5>William L. Wang</font>, 
<font size=2.5>Amanda J. Gellis</font>, 
<font size=2.5>David E. Carlson</font>, 
<font size=2.5>Dmitriy Aronov</font>, 
<font size=2.5>Winrich A. Freiwald</font>, 
<font size=2.5>Fan Wang</font>, 
<font size=2.5>Bence P. Ölveczky</font><br>
<font size=2.5>In Nature Methods 2021 </font><br>
<a href="https://www.nature.com/articles/s41592-021-01106-6.pdf"><img src="data/paper.png"></a> 
<a href="https://github.com/spoonsso/DANNCE"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-3d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-3d-9cf"></a><a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a><a href="https://img.shields.io/badge/animal-monkey-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-monkey-yellowgreen"></a><a href="https://img.shields.io/badge/animal-bird-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-bird-yellowgreen"></a><a href="https://img.shields.io/badge/topic-dataset-orange" align="bottom"><img src="https://img.shields.io/badge/topic-dataset-orange"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://yufu-wang.github.io/aves/"><img src="teasers/Wang2021.jpg"/></a></td>
<td align="left" width=550><em>Birds of a Feather: Capturing Avian Shape Models from Images</em><br>
<a href="https://yufu-wang.github.io/"><font size=2.5>Yufu Wang</font></a>, 
<a href="https://www.seas.upenn.edu/~nkolot/"><font size=2.5>Nikos Kolotouros</font></a>, 
<a href="https://www.cis.upenn.edu/~kostas/"><font size=2.5>Kostas Daniilidis</font></a>, 
<a href="https://www.ocf.berkeley.edu/~badger/"><font size=2.5>Marc Badger</font></a><br>
<font size=2.5>In CVPR 2021 </font><br>
<a href="https://arxiv.org/pdf/2105.09396.pdf"><img src="data/paper.png"></a> 
<a href="https://yufu-wang.github.io/aves/"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/animal-bird-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-bird-yellowgreen"></a><a href="https://img.shields.io/badge/datatype-mesh-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-mesh-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Corcoran2021.jpg"/></a></td>
<td align="left" width=550><em>ThruTracker: Open-Source Software for 2-D and 3-D Animal Video Tracking</em><br>
<font size=2.5>Aaron J. Corcoran</font>, 
<font size=2.5>Michael R. Schirmacher</font>, 
<font size=2.5>Eric Black</font>, 
<a href="https://biomech.web.unc.edu/people/"><font size=2.5>Tyson L. Hedrick</font></a><br>
<font size=2.5>In biorxiv 2021 </font><br>
<a href="https://www.biorxiv.org/content/10.1101/2021.05.12.443854v1.full.pdf"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/datatype-2d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-2d-9cf"></a><a href="https://img.shields.io/badge/datatype-3d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-3d-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://behavioratlas.tech/"><img src="teasers/Huang2020.jpg"/></a></td>
<td align="left" width=550><em>A Hierarchical 3D-motion Learning Framework for Animal Spontaneous Behavior Mapping</em><br>
<font size=2.5>Kang Huang</font>, 
<font size=2.5>Yaning Han</font>, 
<font size=2.5>Ke Chen</font>, 
<font size=2.5>Hongli Pan</font>, 
<font size=2.5>Wenling Yi</font>, 
<font size=2.5>Xiaoxi Li</font>, 
<font size=2.5>Siyuan Liu</font>, 
<a href="http://wanglab.siat.ac.cn/wanglab_en/index.php?a=lab_members"><font size=2.5>Liping Wang</font></a>, 
<a href="https://www.researchgate.net/profile/Pengfei_Wei2"><font size=2.5>Pengfei Wei</font></a><br>
<font size=2.5>In Nature Communications 2021 </font><br>
<a href="https://doi.org/10.1101/2020.09.14.295808"><img src="data/paper.png"></a> 
<a href="https://behavioratlas.tech/"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-3d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-3d-9cf"></a><a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a><a href="https://img.shields.io/badge/topic-behavior-orange" align="bottom"><img src="https://img.shields.io/badge/topic-behavior-orange"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Ziegler2021.jpg"/></a></td>
<td align="left" width=550><em>Big behavior: challenges and opportunities in a new era of deep behavior profiling</em><br>
<font size=2.5>Lukas von Ziegler</font>, 
<font size=2.5>Oliver Sturman</font>, 
<font size=2.5>Johannes Bohacek</font><br>
<font size=2.5>In Neuropsychopharmacology 2021 </font><br>
<a href="https://www.nature.com/articles/s41386-020-0751-7"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/topic-behavior-orange" align="bottom"><img src="https://img.shields.io/badge/topic-behavior-orange"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://github.com/ubcbraincircuits/mCBF"><img src="teasers/Bolanos2021.jpg"/></a></td>
<td align="left" width=550><em>A three-dimensional virtual mouse generates synthetic training data for behavioral analysis</em><br>
<font size=2.5>Luis A. Bolaños</font>, 
<font size=2.5>Dongsheng Xiao</font>, 
<font size=2.5>Nancy L. Ford</font>, 
<font size=2.5>Jeff M. LeDue</font>, 
<font size=2.5>Pankaj K. Gupta</font>, 
<font size=2.5>Carlos Doebeli</font>, 
<font size=2.5>Hao Hu</font>, 
<font size=2.5>Helge Rhodin</font>, 
<font size=2.5>Timothy H. Murphy</font><br>
<font size=2.5>In Nature Methods (Brief Communication) 2021 </font>(<b><font size=2.5>cover</font></b>)<br>
<a href="https://www.nature.com/articles/s41592-021-01103-9"><img src="data/paper.png"></a> 
<a href="https://github.com/ubcbraincircuits/mCBF"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a><a href="https://img.shields.io/badge/topic-dataset-orange" align="bottom"><img src="https://img.shields.io/badge/topic-dataset-orange"></a><a href="https://img.shields.io/badge/datatype-mesh-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-mesh-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://github.com/SchwarzNeuroconLab/DeepLabStream"><img src="teasers/Schweihoff2021.jpg"/></a></td>
<td align="left" width=550><em>DeepLabStream enables closed-loop behavioral experiments using deep learning-based markerless, real-time posture detection</em><br>
<font size=2.5>Jens F. Schweihoff</font>, 
<font size=2.5>Matvey Loshakov</font>, 
<font size=2.5>Irina Pavlova</font>, 
<font size=2.5>Laura Kück</font>, 
<font size=2.5>Laura A. Ewell</font>, 
<font size=2.5>Martin K. Schwarz</font><br>
<font size=2.5>In Communications Biology 2021 </font><br>
<a href="https://www.nature.com/articles/s42003-021-01654-9"><img src="data/paper.png"></a> 
<a href="https://github.com/SchwarzNeuroconLab/DeepLabStream"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-2d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-2d-9cf"></a><a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://github.com/chaneyddtt/UDA-Animal-Pose"><img src="teasers/Li2021.jpg"/></a></td>
<td align="left" width=550><em>From Synthetic to Real: Unsupervised Domain Adaptation for Animal Pose Estimation</em><br>
<a href="https://chaneyddtt.github.io/"><font size=2.5>Chen Li</font></a>, 
<a href="https://www.comp.nus.edu.sg/~leegh/"><font size=2.5>Gim Hee Lee</font></a><br>
<font size=2.5>In CVPR 2021 </font>(<b><font size=2.5>oral</font></b>)<br>
<a href="https://arxiv.org/pdf/2103.14843.pdf"><img src="data/paper.png"></a> 
<a href="https://github.com/chaneyddtt/UDA-Animal-Pose"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-mesh-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-mesh-9cf"></a><a href="https://img.shields.io/badge/datatype-3d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-3d-9cf"></a><a href="https://img.shields.io/badge/animal-quadruped-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-quadruped-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://lasr-google.github.io/"><img src="teasers/Yang2021.jpg"/></a></td>
<td align="left" width=550><em>LASR: Learning Articulated Shape Reconstruction from a Monocular Video</em><br>
<a href="https://gengshan-y.github.io/"><font size=2.5>Gengshan Yang</font></a>, 
<a href="https://deqings.github.io/"><font size=2.5>Deqing Sun</font></a>, 
<a href="https://varunjampani.github.io/"><font size=2.5>Varun Jampani</font></a>, 
<a href="https://people.csail.mit.edu/drdaniel/"><font size=2.5>Daniel Vlasic</font></a>, 
<a href="https://people.csail.mit.edu/fcole/"><font size=2.5>Forrester Cole</font></a>, 
<font size=2.5>Huiwen Chang</font>, 
<a href="http://www.cs.cmu.edu/~deva/"><font size=2.5>Deva Ramanan</font></a>, 
<a href="https://billf.mit.edu/"><font size=2.5>William T. Freeman</font></a>, 
<a href="https://people.csail.mit.edu/celiu/"><font size=2.5>Ce Liu</font></a><br>
<font size=2.5>In CVPR 2021 </font><br>
<a href="https://arxiv.org/pdf/2105.02976.pdf"><img src="data/paper.png"></a> 
<a href="https://lasr-google.github.io/"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-dense%20surface-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-dense%20surface-9cf"></a><a href="https://img.shields.io/badge/animal-quadruped-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-quadruped-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://github.com/DeepLabCut/DeepLabCut-live"><img src="teasers/Kane2020.jpg"/></a></td>
<td align="left" width=550><em>Real-time, low-latency closed-loop feedback using markerless posture tracking</em><br>
<font size=2.5>Gary Kane</font>, 
<font size=2.5>Gonçalo Lopes</font>, 
<font size=2.5>Jonny L. Saunders</font>, 
<a href="https://www.mathislab.org/people"><font size=2.5>Alexander Mathis</font></a>, 
<font size=2.5>Mackenzie W. Mathis</font><br>
<font size=2.5>In eLife 2020 </font>(<b><font size=2.5>Featured by Nature Methods</font></b>)<br>
<a href="https://elifesciences.org/articles/61909"><img src="data/paper.png"></a> 
<a href="https://github.com/DeepLabCut/DeepLabCut-live"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-2d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-2d-9cf"></a><a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Michaiel2020.jpg"/></a></td>
<td align="left" width=550><em>Dynamics of gaze control during prey capture in freely moving mice</em><br>
<font size=2.5>Angie M Michaiel</font>, 
<font size=2.5>Elliott TT Abe</font>, 
<font size=2.5>Cristopher M Niell</font><br>
<font size=2.5>In eLife 2020 </font><br>
<a href="https://elifesciences.org/articles/57458"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/topic-face-orange" align="bottom"><img src="https://img.shields.io/badge/topic-face-orange"></a><a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Marshall2020.jpg"/></a></td>
<td align="left" width=550><em>Continuous Whole-Body 3D Kinematic Recordings across the Rodent Behavioral Repertoire</em><br>
<font size=2.5>Jesse D. Marshall</font>, 
<font size=2.5>Diego E. Aldarondo</font>, 
<font size=2.5>Timothy W. Dunn</font>, 
<font size=2.5>William L. Wang</font>, 
<font size=2.5>Gordon J. Berman</font>, 
<a href="https://oeb.harvard.edu/people/bence-p-olveczky"><font size=2.5>Bence P. O¨lveczky</font></a><br>
<font size=2.5>In Neuron 2020 </font><br>
<a href="https://www.cell.com/neuron/fulltext/S0896-6273(20)30894-1?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0896627320308941%3Fshowall%3Dtrue"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/topic-dataset-orange" align="bottom"><img src="https://img.shields.io/badge/topic-dataset-orange"></a><a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a><a href="https://img.shields.io/badge/topic-behavior-orange" align="bottom"><img src="https://img.shields.io/badge/topic-behavior-orange"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Geuther2019.jpg"/></a></td>
<td align="left" width=550><em>Robust mouse tracking in complex environments using neural networks</em><br>
<font size=2.5>Brian Q. Geuther</font>, 
<font size=2.5>Sean P. Deats</font>, 
<font size=2.5>Kai J. Fox</font>, 
<font size=2.5>Steve A. Murray</font>, 
<font size=2.5>Robert E. Braun</font>, 
<font size=2.5>Jacqueline K. White</font>, 
<font size=2.5>Elissa J. Chesler</font>, 
<font size=2.5>Cathleen M. Lutz</font>, 
<font size=2.5>Vivek Kumar</font><br>
<font size=2.5>In Communications Biology 2019 </font><br>
<a href="https://www.nature.com/articles/s42003-019-0362-1"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://github.com/ZexinChen/AlphaTracker"><img src="teasers/Chen2020.jpg"/></a></td>
<td align="left" width=550><em>AlphaTracker: A Multi-Animal Tracking and Behavioral Analysis Tool</em><br>
<font size=2.5>Zexin Chen</font>, 
<font size=2.5>Ruihan Zhang</font>, 
<font size=2.5>Yu Eva Zhang</font>, 
<font size=2.5>Haowen Zhou</font>, 
<font size=2.5>Hao-Shu Fang</font>, 
<font size=2.5>Rachel R. Rock</font>, 
<font size=2.5>Aneesh Bal</font>, 
<font size=2.5>Nancy Padilla-Coreano</font>, 
<font size=2.5>Laurel Keyes</font>, 
<font size=2.5>Kay M. Tye</font>, 
<a href="https://www.mvig.org/"><font size=2.5>Cewu Lu</font></a><br>
<font size=2.5>In biorxiv 2020 </font><br>
<a href="https://www.biorxiv.org/content/10.1101/2020.12.04.405159v1.full.pdf"><img src="data/paper.png"></a> 
<a href="https://github.com/ZexinChen/AlphaTracker"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-2d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-2d-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://drive.google.com/drive/folders/1W79W1m1JQNvL9bDoqBPhwOXqtyz0gc24?usp=sharing"><img src="teasers/Wu2020-1.jpg"/></a></td>
<td align="left" width=550><em>Deep Graph Pose: a semi-supervised deep graphical model for improved animal pose tracking</em><br>
<font size=2.5>Anqi Wu</font>, 
<font size=2.5>E. Kelly Buchanan</font>, 
<font size=2.5>Matthew Whiteway</font>, 
<font size=2.5>Michael Schartner</font>, 
<font size=2.5>Guido Meijer</font>, 
<font size=2.5>Jean-Paul Noel</font>, 
<font size=2.5>Erica Rodriguez</font>, 
<font size=2.5>Claire Everett</font>, 
<font size=2.5>Amy Norovich</font>, 
<font size=2.5>Evan Schaffer</font>, 
<font size=2.5>Neeli Mishra</font>, 
<font size=2.5>C. Daniel Salzman</font>, 
<font size=2.5>Dora Angelaki</font>, 
<font size=2.5>Andrés Bendesky</font>, 
<font size=2.5>The International Brain Laboratory</font>, 
<font size=2.5>John Cunningham</font>, 
<a href="http://www.stat.columbia.edu/~liam/"><font size=2.5>Liam Paninski</font></a><br>
<font size=2.5>In NeurIPS 2020 </font><br>
<a href="https://www.biorxiv.org/content/biorxiv/early/2020/08/22/2020.08.20.259705.full.pdf"><img src="data/paper.png"></a> 
<a href="https://drive.google.com/drive/folders/1W79W1m1JQNvL9bDoqBPhwOXqtyz0gc24?usp=sharing"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-2d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-2d-9cf"></a><a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Nilsson2020.jpg"/></a></td>
<td align="left" width=550><em>Simple Behavioral Analysis (SimBA)-an open source toolkit for computer classification of complex social behaviors in experimental animals</em><br>
<font size=2.5>Simon RO Nilsson</font>, 
<font size=2.5>Nastacia L. Goodwin</font>, 
<font size=2.5>Jia Jie Choong</font>, 
<font size=2.5>Sophia Hwang</font>, 
<font size=2.5>Hayden R Wright</font>, 
<font size=2.5>Zane C Norville</font>, 
<font size=2.5>Xiaoyu Tong</font>, 
<font size=2.5>Dayu Lin</font>, 
<font size=2.5>Brandon S. Bentzley</font>, 
<font size=2.5>Neir Eshel</font>, 
<font size=2.5>Ryan J McLaughlin</font>, 
<a href="https://goldenneurolab.com/people"><font size=2.5>Sam A. Golden</font></a><br>
<font size=2.5>In biorxiv 2020 </font><br>
<a href="https://doi.org/10.1101/2020.04.19.049452"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/datatype-2d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-2d-9cf"></a><a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://sleap.ai/"><img src="teasers/Pereira2020.jpg"/></a></td>
<td align="left" width=550><em>SLEAP: Multi-animal pose tracking</em><br>
<a href="https://biophysics.princeton.edu/people/talmo-pereira"><font size=2.5>Talmo D. Pereira</font></a>, 
<font size=2.5>Nathaniel Tabris</font>, 
<font size=2.5>Junyu Li</font>, 
<font size=2.5>Shruthi Ravindranath</font>, 
<font size=2.5>Eleni S. Papadoyannis</font>, 
<font size=2.5>Z. Yan Wang</font>, 
<font size=2.5>David M. Turner</font>, 
<font size=2.5>Grace McKenzie-Smith</font>, 
<font size=2.5>Sarah D. Kocher</font>, 
<font size=2.5>Annegret L. Falkner</font>, 
<font size=2.5>Joshua W. Shaevitz</font>, 
<a href="https://murthylab.princeton.edu/mala-murthy"><font size=2.5>Mala Murthy</font></a><br>
<font size=2.5>In biorxiv 2020 </font><br>
<a href="https://doi.org/10.1101/2020.08.31.276246"><img src="data/paper.png"></a> 
<a href="https://sleap.ai/"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-2d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-2d-9cf"></a><a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a><a href="https://img.shields.io/badge/animal-fly-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-fly-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Walter2020.jpg"/></a></td>
<td align="left" width=550><em>TRex, a fast multi-animal tracking system with markerless identification, 2D body posture estimation and visual field reconstruction</em><br>
<a href="https://www.orn.mpg.de/person/45292/409958"><font size=2.5>Tristan Walter</font></a>, 
<a href="http://collectivebehaviour.com/"><font size=2.5>Iain D Couzin</font></a><br>
<font size=2.5>In biorxiv 2020 </font><br>
<a href="https://www.biorxiv.org/content/10.1101/2020.10.14.338996v1.full.pdf"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a><a href="https://img.shields.io/badge/datatype-2d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-2d-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://lmb.informatik.uni-freiburg.de/projects/freipose/"><img src="teasers/Zimmermann2020.jpg"/></a></td>
<td align="left" width=550><em>FreiPose: A Deep Learning Framework for Precise Animal Motion Capture in 3D Spaces</em><br>
<a href="https://lmb.informatik.uni-freiburg.de/people/zimmermc/"><font size=2.5>Christian Zimmermann</font></a>, 
<font size=2.5>Artur Schneider</font>, 
<font size=2.5>Mansour Alyahyay</font>, 
<a href="https://lmb.informatik.uni-freiburg.de/people/brox/"><font size=2.5>Thomas Brox</font></a>, 
<a href="https://www.optophysiology.uni-freiburg.de/labmembers/diester/"><font size=2.5>Ilka Diester</font></a><br>
<font size=2.5>In biorxiv 2020 </font><br>
<a href="https://www.biorxiv.org/content/10.1101/2020.02.27.967620v1"><img src="data/paper.png"></a> 
<a href="https://lmb.informatik.uni-freiburg.de/projects/freipose/"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a><a href="https://img.shields.io/badge/datatype-3d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-3d-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Zhang2020.jpg"/></a></td>
<td align="left" width=550><em>Multiview Supervision By Registration</em><br>
<font size=2.5>Yilun Zhang</font>, 
<a href="https://www-users.cs.umn.edu/~hspark/"><font size=2.5>Hyun Soo Park</font></a><br>
<font size=2.5>In WACV 2020 </font><br>
<a href="https://arxiv.org/abs/1811.11251"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/animal-monkey-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-monkey-yellowgreen"></a><a href="https://img.shields.io/badge/datatype-3d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-3d-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Dolensek2020.jpg"/></a></td>
<td align="left" width=550><em>Facial expressions of emotion states and their neuronal correlates in mice</em><br>
<font size=2.5>Nejc Dolensek</font>, 
<font size=2.5>Daniel A. Gehrlach</font>, 
<a href="https://muckrack.com/alexandra-s-klein"><font size=2.5>Alexandra S. Klein</font></a>, 
<a href="https://www.neuro.mpg.de/gogolla"><font size=2.5>Nadine Gogolla</font></a><br>
<font size=2.5>In Science 2020 </font><br>
<a href="https://science.sciencemag.org/content/368/6486/89.full#:~:text=Facial%20expressions%20thus%20provide%20a%20means%20to%20infer,hormonal%2C%20and%20autonomic%20responses%20aimed%20at%20promoting%20survival."><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a><a href="https://img.shields.io/badge/topic-face-orange" align="bottom"><img src="https://img.shields.io/badge/topic-face-orange"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Fangbemi2020.jpg"/></a></td>
<td align="left" width=550><em>ZooBuilder: 2D and 3D Pose Estimation for Quadrupeds Using Synthetic Data</em><br>
<font size=2.5>Abassin Sourou Fangbemi</font>, 
<font size=2.5>Yi Fei Lu</font>, 
<font size=2.5>Mao Yuan Xu</font>, 
<font size=2.5>Xiao Wu Luo</font>, 
<font size=2.5>Alexis Rolland</font>, 
<font size=2.5>Chedy Raissi</font><br>
<font size=2.5>In SCA (ACM Siggraph/Eurographics Symposium on Computer Animation) 2020 </font><br>
<a href="https://export.arxiv.org/abs/2009.05389"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/animal-quadruped-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-quadruped-yellowgreen"></a><a href="https://img.shields.io/badge/datatype-2d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-2d-9cf"></a><a href="https://img.shields.io/badge/datatype-3d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-3d-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Mathis2020.jpg"/></a></td>
<td align="left" width=550><em>A Primer on Motion Capture with Deep Learning: Principles, Pitfalls and Perspectives</em><br>
<a href="http://www.people.fas.harvard.edu/~amathis/"><font size=2.5>Alexander Mathis</font></a>, 
<font size=2.5>Steffen Schneider</font>, 
<font size=2.5>Jessy Lauer</font>, 
<a href="https://scholar.harvard.edu/mwamoroso/home"><font size=2.5>Mackenzie W. Mathis</font></a><br>
<font size=2.5>In Neuron 2020 </font><br>
<a href="https://arxiv.org/pdf/2009.00564.pdf"><img src="data/paper.png"></a> 
</td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Pereira2020-1.jpg"/></a></td>
<td align="left" width=550><em>Quantifying behavior to understand the brain</em><br>
<a href="https://biophysics.princeton.edu/people/talmo-pereira"><font size=2.5>Talmo D. Pereira</font></a>, 
<a href="https://molbiod.princeton.edu/people/joshua-w-shaevitz"><font size=2.5>Joshua W. Shaevitz</font></a>, 
<a href="htps://murthylab.princeton.edu/mala-murthy"><font size=2.5>Mala Murthy</font></a><br>
<font size=2.5>In Nature Neuroscience 2020 </font>(<b><font size=2.5>review article</font></b>)<br>
<a href="https://www.nature.com/articles/s41593-020-00734-z"><img src="data/paper.png"></a> 
</td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Nourizonoz2020.jpg"/></a></td>
<td align="left" width=550><em>EthoLoop: automated closed-loop neuroethology in naturalistic environments</em><br>
<font size=2.5>Ali Nourizonoz</font>, 
<font size=2.5>Robert Zimmermann</font>, 
<font size=2.5>Chun Lum Andy Ho</font>, 
<font size=2.5>Sebastien Pellat</font>, 
<font size=2.5>Yannick Ormen</font>, 
<font size=2.5>Clément Prévost-Solié</font>, 
<font size=2.5>Gilles Reymond</font>, 
<font size=2.5>Fabien Pifferi</font>, 
<font size=2.5>Fabienne Aujard</font>, 
<font size=2.5>Anthony Herrel</font>, 
<a href="https://www.unige.ch/medecine/neuf/en/"><font size=2.5>Daniel Huber</font></a><br>
<font size=2.5>In Nature Methods 2020 </font>(<b><font size=2.5>cover</font></b>)<br>
<a href="https://pubmed.ncbi.nlm.nih.gov/32994566/"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/animal-mouse%20lemur-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse%20lemur-yellowgreen"></a><a href="https://img.shields.io/badge/datatype-3d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-3d-9cf"></a><a href="https://img.shields.io/badge/topic-behavior-orange" align="bottom"><img src="https://img.shields.io/badge/topic-behavior-orange"></a><a href="https://img.shields.io/badge/topic-brain-orange" align="bottom"><img src="https://img.shields.io/badge/topic-brain-orange"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="openmonkeystudio.org"><img src="teasers/Bala2020.jpg"/></a></td>
<td align="left" width=550><em>Automated Markerless Pose Estimation in Freely Moving Macaques using OpenMonkeyStudio</em><br>
<font size=2.5>Praneet C. Bala</font>, 
<font size=2.5>Benjamin R. Eisenreich</font>, 
<font size=2.5>Seng Bum Michael Yoo</font>, 
<font size=2.5>Benjamin Y. Hayden</font>, 
<a href="https://www-users.cs.umn.edu/~hspark/"><font size=2.5>Hyun Soo Park</font></a>, 
<a href="https://med.umn.edu/bio/medical-discovery-teams/jan-zimmermann"><font size=2.5>Jan Zimmermann</font></a><br>
<font size=2.5>In Nature Communications 2020 </font><br>
<a href="https://www.biorxiv.org/content/10.1101/2020.01.31.928861v1"><img src="data/paper.png"></a> 
<a href="openmonkeystudio.org"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/animal-monkey-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-monkey-yellowgreen"></a><a href="https://img.shields.io/badge/datatype-3d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-3d-9cf"></a><a href="https://img.shields.io/badge/topic-dataset-orange" align="bottom"><img src="https://img.shields.io/badge/topic-dataset-orange"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://marcbadger.github.io/avian-mesh/"><img src="teasers/Badger2020.jpg"/></a></td>
<td align="left" width=550><em>3D Bird Reconstruction: a Dataset, Model, and Shape Recovery from a Single View</em><br>
<a href="https://www.ocf.berkeley.edu/~badger/"><font size=2.5>Marc Badger</font></a>, 
<a href="https://yufu-wang.github.io/"><font size=2.5>Yufu Wang</font></a>, 
<a href="https://www.seas.upenn.edu/~adarshm/"><font size=2.5>Adarsh Modh</font></a>, 
<a href="https://aperkes.github.io/"><font size=2.5>Ammon Perkes</font></a>, 
<a href="https://www.seas.upenn.edu/~nkolot/"><font size=2.5>Nikos Kolotouros</font></a>, 
<a href="http://pfrommer.us/"><font size=2.5>Bernd Pfrommer</font></a>, 
<a href="https://web.sas.upenn.edu/marcschmidtlab/pages/people/"><font size=2.5>Marc F. Schmidt</font></a>, 
<a href="https://www.cis.upenn.edu/~kostas/"><font size=2.5>Kostas Daniilidis</font></a><br>
<font size=2.5>In ECCV 2020 </font><br>
<a href="https://arxiv.org/abs/2008.06133"><img src="data/paper.png"></a> 
<a href="https://marcbadger.github.io/avian-mesh/"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/animal-bird-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-bird-yellowgreen"></a><a href="https://img.shields.io/badge/datatype-mesh-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-mesh-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Biggs2020.jpg"/></a></td>
<td align="left" width=550><em>Who Left the Dogs Out? 3D Animal Reconstruction with Expectation Maximization in the Loop</em><br>
<a href="http://mi.eng.cam.ac.uk/~bjb56/"><font size=2.5>Benjamin Biggs</font></a>, 
<a href="https://uk.linkedin.com/in/ollie-boyne"><font size=2.5>Oliver Boyne</font></a>, 
<a href="http://www.jjcvision.com/"><font size=2.5>James Charles</font></a>, 
<a href="https://www.microsoft.com/en-us/research/people/awf/"><font size=2.5>Andrew Fitzgibbon</font></a>, 
<a href="https://mi.eng.cam.ac.uk/~cipolla/"><font size=2.5>Roberto Cipolla</font></a><br>
<font size=2.5>In ECCV 2020 </font><br>
<a href="https://arxiv.org/abs/2007.11110"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/animal-dog-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-dog-yellowgreen"></a><a href="https://img.shields.io/badge/datatype-mesh-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-mesh-9cf"></a><a href="https://img.shields.io/badge/animal-quadruped-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-quadruped-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://shubham-goel.github.io/ucmr/"><img src="teasers/Goel2020.jpg"/></a></td>
<td align="left" width=550><em>Shape and Viewpoint without Keypoints</em><br>
<a href="https://people.eecs.berkeley.edu/~shubham-goel/"><font size=2.5>Shubham Goel</font></a>, 
<a href="https://people.eecs.berkeley.edu/~kanazawa/"><font size=2.5>Angjoo Kanazawa</font></a>, 
<a href="https://people.eecs.berkeley.edu/~malik/"><font size=2.5>Jitendra Malik</font></a><br>
<font size=2.5>In ECCV 2020 </font><br>
<a href="https://arxiv.org/pdf/2007.10982.pdf"><img src="data/paper.png"></a> 
<a href="https://shubham-goel.github.io/ucmr/"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-dense%20surface-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-dense%20surface-9cf"></a><a href="https://img.shields.io/badge/animal-bird-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-bird-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Shi2020.jpg"/></a></td>
<td align="left" width=550><em>Deep Cross-species Feature Learning for Animal Face Recognition via Residual Interspecies Equivariant Network</em><br>
<font size=2.5>Xiao Shi</font>, 
<font size=2.5>Chenxue Yang</font>, 
<font size=2.5>Xue Xia</font>, 
<a href="http://aii.caas.cn/bsgk/ywbm/nyxxjzsyb/xzbm3/203034.htm"><font size=2.5>Xiujuan Chai</font></a><br>
<font size=2.5>In ECCV 2020 </font><br>
<a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123720664.pdf"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/topic-face-orange" align="bottom"><img src="https://img.shields.io/badge/topic-face-orange"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://github.com/CAMERA-Bath/RGBD-Dog#:~:text=%20RGBD-Dog%3A%20Predicting%20Canine%20Pose%20from%20RGBD%20Sensors,5%20Citation.%20%206%20Contact.%20%20More%20"><img src="teasers/Kearney2020.jpg"/></a></td>
<td align="left" width=550><em>RGBD-Dog: Predicting Canine Pose from RGBD Sensors</em><br>
<a href="https://researchportal.bath.ac.uk/en/persons/sinead-kearney"><font size=2.5>Sinead Kearney</font></a>, 
<a href="https://wbli.me/"><font size=2.5>Wenbin Li</font></a>, 
<font size=2.5>Martin Parsons</font>, 
<a href="http://kimki.unist.ac.kr/"><font size=2.5>Kwang In Kim</font></a>, 
<a href="http://www.cs.bath.ac.uk/~dpc/"><font size=2.5>Darren Cosker</font></a><br>
<font size=2.5>In CVPR 2020 </font><br>
<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Kearney_RGBD-Dog_Predicting_Canine_Pose_from_RGBD_Sensors_CVPR_2020_paper.pdf"><img src="data/paper.png"></a> 
<a href="https://github.com/CAMERA-Bath/RGBD-Dog#:~:text=%20RGBD-Dog%3A%20Predicting%20Canine%20Pose%20from%20RGBD%20Sensors,5%20Citation.%20%206%20Contact.%20%20More%20"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/animal-dog-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-dog-yellowgreen"></a><a href="https://img.shields.io/badge/topic-dataset-orange" align="bottom"><img src="https://img.shields.io/badge/topic-dataset-orange"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://fdmaproject.wordpress.com/"><img src="teasers/Khan2020.jpg"/></a></td>
<td align="left" width=550><em>AnimalWeb: A Large-Scale Hierarchical Dataset of Annotated Animal Faces</em><br>
<font size=2.5>Muhammad Haris Khan</font>, 
<font size=2.5>John McDonagh</font>, 
<font size=2.5>Salman Khan</font>, 
<font size=2.5>Muhammad Shahabuddin</font>, 
<font size=2.5>Aditya Arora</font>, 
<font size=2.5>Fahad Shahbaz Khan</font>, 
<font size=2.5>Ling Shao</font>, 
<a href="http://www.cs.nott.ac.uk/~pszyt/"><font size=2.5>Georgios Tzimiropoulos</font></a><br>
<font size=2.5>In CVPR 2020 </font><br>
<a href="https://arxiv.org/abs/1909.04951"><img src="data/paper.png"></a> 
<a href="https://fdmaproject.wordpress.com/"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/topic-face-orange" align="bottom"><img src="https://img.shields.io/badge/topic-face-orange"></a><a href="https://img.shields.io/badge/datatype-2d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-2d-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://nileshkulkarni.github.io/acsm/"><img src="teasers/Kulkarni2020.png"/></a></td>
<td align="left" width=550><em>Articulation Aware Canonical Surface Mapping</em><br>
<a href="https://nileshkulkarni.github.io/"><font size=2.5>Nilesh Kulkarni</font></a>, 
<a href="http://www.cs.cmu.edu/~abhinavg/"><font size=2.5>Abhinav Gupta</font></a>, 
<a href="http://web.eecs.umich.edu/~fouhey/"><font size=2.5>David F. Fouhey</font></a>, 
<a href="https://shubhtuls.github.io/"><font size=2.5>Shubham Tulsiani</font></a><br>
<font size=2.5>In CVPR 2020 </font><br>
<a href="https://arxiv.org/pdf/2004.00614.pdf"><img src="data/paper.png"></a> 
<a href="https://nileshkulkarni.github.io/acsm/"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-dense%20surface-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-dense%20surface-9cf"></a><a href="https://img.shields.io/badge/animal-quadruped-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-quadruped-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://github.com/siyliepfl/deformation-aware-unpaired-image-translation"><img src="teasers/Li2020.JPG"/></a></td>
<td align="left" width=550><em>Deformation-aware Unpaired Image Translation for Pose Estimation on Laboratory Animals</em><br>
<a href="https://siyliepfl.github.io/"><font size=2.5>Siyuan Li</font></a>, 
<a href="https://semihgunel.com/"><font size=2.5>Semih Gunel</font></a>, 
<font size=2.5>Mirela Ostrek</font>, 
<font size=2.5>Pavan Ramdya</font>, 
<font size=2.5>Pascal Fua</font>, 
<a href="https://www.cs.ubc.ca/~rhodin/"><font size=2.5>Helge Rhodin</font></a><br>
<font size=2.5>In CVPR 2020 </font><br>
<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Deformation-Aware_Unpaired_Image_Translation_for_Pose_Estimation_on_Laboratory_Animals_CVPR_2020_paper.pdf"><img src="data/paper.png"></a> 
<a href="https://github.com/siyliepfl/deformation-aware-unpaired-image-translation"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-3d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-3d-9cf"></a><a href="https://img.shields.io/badge/datatype-mesh-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-mesh-9cf"></a><a href="https://img.shields.io/badge/animal-fly-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-fly-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://github.com/JitengMu/Learning-from-Synthetic-Animals"><img src="teasers/Mu2020.JPG"/></a></td>
<td align="left" width=550><em>Learning from Synthetic Animals</em><br>
<font size=2.5>Jiteng Mu</font>, 
<a href="https://weichaoqiu.com/"><font size=2.5>Weichao Qiu</font></a>, 
<a href="https://www.cs.jhu.edu/hager/"><font size=2.5>Gregory Hager</font></a>, 
<a href="http://www.cs.jhu.edu/~ayuille/"><font size=2.5>Alan Yuille</font></a><br>
<font size=2.5>In CVPR 2020 </font>(<b><font size=2.5>oral</font></b>)<br>
<a href="https://arxiv.org/abs/1912.08265"><img src="data/paper.png"></a> 
<a href="https://github.com/JitengMu/Learning-from-Synthetic-Animals"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-mesh-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-mesh-9cf"></a><a href="https://img.shields.io/badge/datatype-2d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-2d-9cf"></a><a href="https://img.shields.io/badge/animal-quadruped-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-quadruped-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://vap.aau.dk/3d-zef/"><img src="teasers/Pedersen2020.jpg"/></a></td>
<td align="left" width=550><em>3D-ZeF: A 3D Zebrafish Tracking Benchmark Dataset</em><br>
<a href="https://vbn.aau.dk/en/persons/141158"><font size=2.5>Malte Pedersen</font></a>, 
<font size=2.5>Joakim Bruslund Haurum</font>, 
<a href="https://vbn.aau.dk/en/persons/138111"><font size=2.5>Stefan Hein Bengtson</font></a>, 
<a href="https://vbn.aau.dk/en/persons/103282"><font size=2.5>Thomas B. Moeslund</font></a><br>
<font size=2.5>In CVPR 2020 </font><br>
<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Pedersen_3D-ZeF_A_3D_Zebrafish_Tracking_Benchmark_Dataset_CVPR_2020_paper.pdf"><img src="data/paper.png"></a> 
<a href="https://vap.aau.dk/3d-zef/"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-3d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-3d-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://gdude.de/densepose-evolution/"><img src="teasers/Sanakoyeu2020.jpg"/></a></td>
<td align="left" width=550><em>Transferring Dense Pose to Proximal Animal Classes</em><br>
<a href="https://gdude.de/"><font size=2.5>Artsiom Sanakoyeu</font></a>, 
<a href="https://research.fb.com/people/khalidov-vasil/"><font size=2.5>Vasil Khalidov</font></a>, 
<a href="https://www.maureenmccarthyphd.com/"><font size=2.5>Maureen S. McCarthy</font></a>, 
<a href="https://www.robots.ox.ac.uk/~vedaldi/"><font size=2.5>Andrea Vedaldi</font></a>, 
<a href="https://nneverova.github.io/"><font size=2.5>Natalia Neverova</font></a><br>
<font size=2.5>In CVPR 2020 </font><br>
<a href="https://arxiv.org/abs/2003.00080"><img src="data/paper.png"></a> 
<a href="https://gdude.de/densepose-evolution/"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-dense%20surface-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-dense%20surface-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://elliottwu.com/projects/unsup3d/"><img src="teasers/Wu2020.jpg"/></a></td>
<td align="left" width=550><em>Unsupervised Learning of Probably Symmetric Deformable 3D Objects from Images in the Wild</em><br>
<a href="https://elliottwu.com/"><font size=2.5>Shangzhe Wu</font></a>, 
<a href="https://chrirupp.github.io/"><font size=2.5>Christian Rupprecht</font></a>, 
<a href="http://www.robots.ox.ac.uk/~vedaldi/"><font size=2.5>Andrea Vedaldi</font></a><br>
<font size=2.5>In CVPR 2020 </font>(<b><font size=2.5>Best Paper Award</font></b>)<br>
<a href="https://arxiv.org/abs/1911.11130"><img src="data/paper.png"></a> 
<a href="https://elliottwu.com/projects/unsup3d/"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/animal-cat-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-cat-yellowgreen"></a><a href="https://img.shields.io/badge/topic-face-orange" align="bottom"><img src="https://img.shields.io/badge/topic-face-orange"></a><a href="https://img.shields.io/badge/datatype-dense%20surface-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-dense%20surface-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://github.com/jgraving/deepposekit"><img src="teasers/Graving2019.jpg"/></a></td>
<td align="left" width=550><em>DeepPoseKit, a software toolkit for fast and robust animal pose estimation using deep learning</em><br>
<a href="https://jakegraving.com/files/cv/jacob_graving_cv.pdf"><font size=2.5>Jacob M. Graving</font></a>, 
<a href="https://www.danielchae.com/"><font size=2.5>Daniel Chae</font></a>, 
<font size=2.5>Hemal Naik</font>, 
<font size=2.5>Liang Li</font>, 
<font size=2.5>Benjamin Koger</font>, 
<a href="http://www.blaircostelloe.com/"><font size=2.5>Blair R. Costelloe</font></a>, 
<a href="http://collectivebehaviour.com/people/couzin-iain/#:~:text=Iain%20Couzin%20is%20Director%20of%20the%20Max%20Planck,Fellow%20in%20the%20Sciences%20at%20Balliol%20College%2C%20Oxford."><font size=2.5>Iain D. Couzin</font></a><br>
<font size=2.5>In eLife 2019 </font><br>
<a href="https://www.biorxiv.org/content/10.1101/620245v7"><img src="data/paper.png"></a> 
<a href="https://github.com/jgraving/deepposekit"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a><a href="https://img.shields.io/badge/datatype-2d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-2d-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://github.com/DeepLabCut/DeepLabCut/blob/master/README.md"><img src="teasers/Nath2019.jpg"/></a></td>
<td align="left" width=550><em>Using DeepLabCut for 3D markerless pose estimation across species and behaviors</em><br>
<font size=2.5>Tanmay Nath</font>, 
<a href="http://www.people.fas.harvard.edu/~amathis/"><font size=2.5>Alexander Mathis</font></a>, 
<font size=2.5>An Chi Chen</font>, 
<font size=2.5>Amir Patel</font>, 
<a href="http://bethgelab.org/"><font size=2.5>Matthias Bethge</font></a>, 
<a href="https://scholar.harvard.edu/mwamoroso/home"><font size=2.5>Mackenzie Weygandt Mathis</font></a><br>
<font size=2.5>In Nature Protocols 2019 </font>(<b><font size=2.5>cover</font></b>)<br>
<a href="https://www.nature.com/articles/s41596-019-0176-0"><img src="data/paper.png"></a> 
<a href="https://github.com/DeepLabCut/DeepLabCut/blob/master/README.md"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-3d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-3d-9cf"></a><a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://github.com/talmo/leap"><img src="teasers/Pereira2019.jpg"/></a></td>
<td align="left" width=550><em>Fast animal pose estimation using deep neural networks</em><br>
<a href="https://biophysics.princeton.edu/people/talmo-pereira"><font size=2.5>Talmo D. Pereira</font></a>, 
<a href="https://olveczkylab.oeb.harvard.edu/people/diego-etiony-aldarondo"><font size=2.5>Diego E. Aldarondo</font></a>, 
<font size=2.5>Lindsay Willmore</font>, 
<a href="Mikhail Kislin"><font size=2.5>Mikhail Kislin</font></a>, 
<a href="https://scholar.princeton.edu/wanglab/people/samuel-s-h-wang"><font size=2.5>Samuel S.-H. Wang</font></a>, 
<a href="https://murthylab.princeton.edu/mala-murthy"><font size=2.5>Mala Murthy</font></a>, 
<a href="https://molbiod.princeton.edu/people/joshua-w-shaevitz"><font size=2.5>Joshua W. Shaevitz</font></a><br>
<font size=2.5>In Nature Methods 2019 </font><br>
<a href="https://www.nature.com/articles/s41592-018-0234-5"><img src="data/paper.png"></a> 
<a href="https://github.com/talmo/leap"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-2d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-2d-9cf"></a><a href="https://img.shields.io/badge/animal-fly-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-fly-yellowgreen"></a><a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a><a href="https://img.shields.io/badge/topic-behavior-orange" align="bottom"><img src="https://img.shields.io/badge/topic-behavior-orange"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://edspace.american.edu/openbehavior/2018/12/05/live-mouse-tracker/"><img src="teasers/Chaumont2019.jpg"/></a></td>
<td align="left" width=550><em>Real-time analysis of the behaviour of groups of mice via a depth-sensing camera and machine learning</em><br>
<a href="https://research.pasteur.fr/en/member/fabrice-de-chaumont/"><font size=2.5>Fabrice de Chaumont</font></a>, 
<font size=2.5>Elodie Ey</font>, 
<font size=2.5>Nicolas Torquet</font>, 
<font size=2.5>Thibault Lagache</font>, 
<font size=2.5>Stéphane Dallongeville</font>, 
<font size=2.5>Albane Imbert</font>, 
<font size=2.5>Thierry Legou</font>, 
<font size=2.5>Anne-Marie Le Sourd</font>, 
<font size=2.5>Philippe Faure</font>, 
<a href="https://research.pasteur.fr/en/member/thomas-bourgeron/"><font size=2.5>Thomas Bourgeron</font></a>, 
<a href="https://research.pasteur.fr/en/member/jean-christophe-olivo-marin/"><font size=2.5>Jean-Christophe Olivo-Marin</font></a><br>
<font size=2.5>In Nature Biomedical Engineering 2019 </font><br>
<a href="https://www.nature.com/articles/s41551-019-0396-1"><img src="data/paper.png"></a> 
<a href="https://edspace.american.edu/openbehavior/2018/12/05/live-mouse-tracker/"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="http://www.jinkuncao.com/animalpose"><img src="teasers/Cao2019.jpg"/></a></td>
<td align="left" width=550><em>Cross-Domain Adaptation for Animal Pose Estimation</em><br>
<a href="http://www.jinkuncao.com/"><font size=2.5>Jinkun Cao</font></a>, 
<font size=2.5>Hongyang Tang</font>, 
<a href="https://fang-haoshu.github.io/"><font size=2.5>Hao-Shu Fang</font></a>, 
<a href="http://xiaoyongshen.me/"><font size=2.5>Xiaoyong Shen</font></a>, 
<a href="https://www.mvig.org/"><font size=2.5>Cewu Lu</font></a>, 
<font size=2.5>Yu-Wing Tai</font><br>
<font size=2.5>In ICCV 2019 </font>(<b><font size=2.5>oral</font></b>)<br>
<a href="https://arxiv.org/abs/1908.05806"><img src="data/paper.png"></a> 
<a href="http://www.jinkuncao.com/animalpose"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-2d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-2d-9cf"></a><a href="https://img.shields.io/badge/animal-quadruped-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-quadruped-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://nileshkulkarni.github.io/csm/"><img src="teasers/Kulkarni2019.jpg"/></a></td>
<td align="left" width=550><em>Canonical Surface Mapping via Geometric Cycle Consistency</em><br>
<a href="https://nileshkulkarni.github.io/"><font size=2.5>Nilesh Kulkarni</font></a>, 
<a href="http://www.cs.cmu.edu/~abhinavg/"><font size=2.5>Abhinav Gupta</font></a>, 
<a href="https://shubhtuls.github.io/"><font size=2.5>Shubham Tulsiani</font></a><br>
<font size=2.5>In ICCV 2019 </font><br>
<a href="https://arxiv.org/pdf/1907.10043.pdf"><img src="data/paper.png"></a> 
<a href="https://nileshkulkarni.github.io/csm/"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-dense%20surface-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-dense%20surface-9cf"></a><a href="https://img.shields.io/badge/animal-quadruped-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-quadruped-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Yao2019.jpg"/></a></td>
<td align="left" width=550><em>MONET: Multiview Semi-supervised Keypoint Detection via Epipolar Divergence</em><br>
<font size=2.5>Yuan Yao</font>, 
<font size=2.5>Yasamin Jafarian</font>, 
<a href="https://www-users.cs.umn.edu/~hspark/"><font size=2.5>Hyun Soo Park</font></a><br>
<font size=2.5>In ICCV 2019 </font><br>
<a href="https://arxiv.org/abs/1806.00104"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/animal-monkey-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-monkey-yellowgreen"></a><a href="https://img.shields.io/badge/datatype-3d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-3d-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://github.com/silviazuffi/smalst"><img src="teasers/Zuffi2019.jpg"/></a></td>
<td align="left" width=550><em>Three-D Safari: Learning to Estimate Zebra Pose, Shape, and Texture from Images "In the Wild"</em><br>
<a href="https://ps.is.tuebingen.mpg.de/person/szuffi"><font size=2.5>Silvia Zuffi</font></a>, 
<a href="https://people.eecs.berkeley.edu/~kanazawa/"><font size=2.5>Angjoo Kanazawa</font></a>, 
<a href="https://www.cs.uic.edu/~tanyabw/"><font size=2.5>Tanya Berger-Wolf</font></a>, 
<a href="https://ps.is.tuebingen.mpg.de/person/black"><font size=2.5>Michael J. Black</font></a><br>
<font size=2.5>In ICCV 2019 </font><br>
<a href="https://arxiv.org/abs/1908.07201"><img src="data/paper.png"></a> 
<a href="https://github.com/silviazuffi/smalst"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-mesh-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-mesh-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="http://www.mousemotorlab.org/deeplabcut"><img src="teasers/Mathis2018.jpg"/></a></td>
<td align="left" width=550><em>DeepLabCut: markerless pose estimation of user-defined body parts with deep learning</em><br>
<a href="http://www.people.fas.harvard.edu/~amathis/"><font size=2.5>Alexander Mathis</font></a>, 
<font size=2.5>Pranav Mamidanna</font>, 
<a href="https://muckrack.com/kevin-m-cury"><font size=2.5>Kevin M. Cury</font></a>, 
<font size=2.5>Taiga Abe</font>, 
<a href="https://vnmurthylab.org/"><font size=2.5>Venkatesh N. Murthy</font></a>, 
<a href="https://scholar.harvard.edu/mwamoroso/home"><font size=2.5>Mackenzie Weygandt Mathis</font></a>, 
<a href="http://bethgelab.org/"><font size=2.5>Matthias Bethge</font></a><br>
<font size=2.5>In Nature Neuroscience 2018 </font><br>
<a href="https://www.nature.com/articles/s41593-018-0209-y"><img src="data/paper.png"></a> 
<a href="http://www.mousemotorlab.org/deeplabcut"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-2d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-2d-9cf"></a><a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a><a href="https://img.shields.io/badge/animal-fly-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-fly-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://akanazawa.github.io/cmr/"><img src="teasers/Kanazawa2018.jpg"/></a></td>
<td align="left" width=550><em>Learning Category-Specific Mesh Reconstruction from Image Collections</em><br>
<a href="https://people.eecs.berkeley.edu/~kanazawa/"><font size=2.5>Angjoo Kanazawa</font></a>, 
<a href="https://shubhtuls.github.io/"><font size=2.5>Shubham Tulsiani</font></a>, 
<a href="https://people.eecs.berkeley.edu/~efros/"><font size=2.5>Alexei A. Efros</font></a>, 
<a href="https://people.eecs.berkeley.edu/~malik/"><font size=2.5>Jitendra Malik</font></a><br>
<font size=2.5>In ECCV 2018 </font><br>
<a href="https://people.eecs.berkeley.edu/~kanazawa/papers/cmr_camera_ready.pdf"><img src="data/paper.png"></a> 
<a href="https://akanazawa.github.io/cmr/"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/animal-bird-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-bird-yellowgreen"></a><a href="https://img.shields.io/badge/datatype-dense%20surface-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-dense%20surface-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="http://smalr.is.tue.mpg.de/"><img src="teasers/Zuffi2018.jpg"/></a></td>
<td align="left" width=550><em>Lions and Tigers and Bears: Capturing Non-Rigid, 3D, Articulated Shape from Images</em><br>
<a href="https://ps.is.tuebingen.mpg.de/person/szuffi"><font size=2.5>Silvia Zuffi</font></a>, 
<a href="https://people.eecs.berkeley.edu/~kanazawa/"><font size=2.5>Angjoo Kanazawa</font></a>, 
<a href="https://ps.is.tuebingen.mpg.de/person/black"><font size=2.5>Michael J. Black</font></a><br>
<font size=2.5>In CVPR 2018 </font>(<b><font size=2.5>spotlight</font></b>)<br>
<a href="http://files.is.tue.mpg.de/black/papers/zuffiCVPR2018.pdf"><img src="data/paper.png"></a> 
<a href="http://smalr.is.tue.mpg.de/"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/animal-quadruped-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-quadruped-yellowgreen"></a><a href="https://img.shields.io/badge/datatype-mesh-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-mesh-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Biggs2018.jpg"/></a></td>
<td align="left" width=550><em>Creatures great and SMAL: Recovering the shape and motion of animals from video</em><br>
<a href="http://mi.eng.cam.ac.uk/~bjb56/"><font size=2.5>Benjamin Biggs</font></a>, 
<a href="http://mi.eng.cam.ac.uk/~tr346/"><font size=2.5>Thomas Roddick</font></a>, 
<a href="https://www.microsoft.com/en-us/research/people/awf/"><font size=2.5>Andrew Fitzgibbon</font></a>, 
<a href="https://mi.eng.cam.ac.uk/~cipolla/"><font size=2.5>Roberto Cipolla</font></a><br>
<font size=2.5>In ACCV 2018 </font>(<b><font size=2.5>oral</font></b>)<br>
<a href="https://arxiv.org/abs/1811.05804"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/animal-quadruped-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-quadruped-yellowgreen"></a><a href="https://img.shields.io/badge/datatype-mesh-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-mesh-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Klibaite2017.jpg"/></a></td>
<td align="left" width=550><em>An unsupervised method for quantifying the behavior of paired animals</em><br>
<font size=2.5>Ugne Klibaite</font>, 
<font size=2.5>Gordon J Berman</font>, 
<font size=2.5>Jessica Cande</font>, 
<font size=2.5>David L Stern</font>, 
<a href="https://molbio.princeton.edu/people/joshua-w-shaevitz"><font size=2.5>Joshua W Shaevitz</font></a><br>
<font size=2.5>In Physical Biology 2017 </font><br>
<a href="https://doi.org/10.1088/1478-3975/aa5c50"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/topic-behavior-orange" align="bottom"><img src="https://img.shields.io/badge/topic-behavior-orange"></a><a href="https://img.shields.io/badge/animal-mouse-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-mouse-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Kanazawa2017.jpg"/></a></td>
<td align="left" width=550><em>Single-View 3D Reconstruction of Animals</em><br>
<a href="https://people.eecs.berkeley.edu/~kanazawa/"><font size=2.5>Angjoo Kanazawa</font></a><br>
<font size=2.5>In Ph.D Thesis 2017 </font><br>
<a href="https://people.eecs.berkeley.edu/~kanazawa/papers/thesis.pdf"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/datatype-mesh-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-mesh-9cf"></a><a href="https://img.shields.io/badge/animal-quadruped-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-quadruped-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="http://smal.is.tue.mpg.de/"><img src="teasers/Zuffi2017.jpg"/></a></td>
<td align="left" width=550><em>3D Menagerie: Modeling the 3D shape and pose of animals</em><br>
<a href="https://ps.is.tuebingen.mpg.de/person/szuffi"><font size=2.5>Silvia Zuffi</font></a>, 
<a href="https://people.eecs.berkeley.edu/~kanazawa/"><font size=2.5>Angjoo Kanazawa</font></a>, 
<a href="https://www.cs.umd.edu/~djacobs/"><font size=2.5>David W. Jacobs</font></a>, 
<a href="https://ps.is.tuebingen.mpg.de/person/black"><font size=2.5>Michael J. Black</font></a><br>
<font size=2.5>In CVPR 2017 </font>(<b><font size=2.5>spotlight</font></b>)<br>
<a href="https://people.eecs.berkeley.edu/~kanazawa/papers/cvpr17_menagerie_camready.pdf"><img src="data/paper.png"></a> 
<a href="http://smal.is.tue.mpg.de/"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-mesh-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-mesh-9cf"></a><a href="https://img.shields.io/badge/animal-quadruped-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-quadruped-yellowgreen"></a><a href="https://img.shields.io/badge/topic-dataset-orange" align="bottom"><img src="https://img.shields.io/badge/topic-dataset-orange"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="none"><img src="teasers/Breslav2016.jpg"/></a></td>
<td align="left" width=550><em>3D Pose Estimation of Flying Animals in Multi-view Video Datasets</em><br>
<a href="http://people.bu.edu/breslav/"><font size=2.5>Mikhail Breslav</font></a><br>
<font size=2.5>In Ph.D Thesis 2016 </font><br>
<a href="https://open.bu.edu/handle/2144/19720"><img src="data/paper.png"></a> 
<a href="https://img.shields.io/badge/animal-bird-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-bird-yellowgreen"></a><a href="https://img.shields.io/badge/datatype-3d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-3d-9cf"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="https://github.com/akanazawa/catdeform"><img src="teasers/Kanazawa2016.jpg"/></a></td>
<td align="left" width=550><em>Learning 3D Deformation of Animals from 2D Images</em><br>
<a href="https://people.eecs.berkeley.edu/~kanazawa/"><font size=2.5>Angjoo Kanazawa</font></a>, 
<a href="https://shaharkov.github.io/"><font size=2.5>Shahar Kovalsky</font></a>, 
<a href="http://www.weizmann.ac.il/math/ronen/home"><font size=2.5>Ronen Basri</font></a>, 
<a href="https://www.cs.umd.edu/~djacobs/"><font size=2.5>David W. Jacobs</font></a><br>
<font size=2.5>In Eurographics 2016 </font>(<b><font size=2.5>Günter Enderle Best Paper Award</font></b>)<br>
<a href="https://people.eecs.berkeley.edu/~kanazawa/papers/cat_eg2016.pdf"><img src="data/paper.png"></a> 
<a href="https://github.com/akanazawa/catdeform"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/datatype-mesh-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-mesh-9cf"></a><a href="https://img.shields.io/badge/animal-cat-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-cat-yellowgreen"></a></td></tr></tbody>


<tbody> <tr> <td align="left" width=250>
<a href="http://www.idtracker.es/"><img src="teasers/Escudero2014.jpg"/></a></td>
<td align="left" width=550><em>idTracker: Tracking individuals in a group by automatic identification of unmarked animals</em><br>
<font size=2.5>Alfonso Pérez-Escudero</font>, 
<font size=2.5>Julián Vicente-Page</font>, 
<font size=2.5>Robert C Hinz</font>, 
<font size=2.5>Sara Arganda</font>, 
<a href="http://www.neuro.fchampalimaud.org/en/person/276/"><font size=2.5>Gonzalo G de Polavieja1</font></a><br>
<font size=2.5>In Nature Methods 2014 </font><br>
<a href="https://www.nature.com/articles/nmeth.2994"><img src="data/paper.png"></a> 
<a href="http://www.idtracker.es/"><img src="data/project.png"></a>
<a href="https://img.shields.io/badge/animal-fly-yellowgreen" align="bottom"><img src="https://img.shields.io/badge/animal-fly-yellowgreen"></a><a href="https://img.shields.io/badge/datatype-2d-9cf" align="bottom"><img src="https://img.shields.io/badge/datatype-2d-9cf"></a></td></tr></tbody>


</table>
<br>

Last updated in Apr 2022
<br>

This repository is inspired by [Cat Papers](https://github.com/junyanz/CatPapers) with some code borrowed from it. Paper and project signs are taken from [http://kesen.realtimerendering.com/](http://kesen.realtimerendering.com/). 